{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.util import bigrams, trigrams, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read the script data into a dataframe\n",
    "df = pd.read_csv('star-trek-transcripts_parsed_voyager.csv', usecols=['season','episode_name','speaker','line'])\n",
    "df = df[df['speaker'].notna()]    # dialogue only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert to lowercase and tokenize the lines (only keep word characters and apostrophes for contractions)\n",
    "df['tokens'] = [nltk.regexp_tokenize(line, pattern=\"[\\w\\']+\") for line in df['line'].str.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "df = df.explode('tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prev_word'] = df['tokens'].shift(periods=1)\n",
    "df['next_word'] = df['tokens'].shift(periods=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>season</th>\n",
       "      <th>speaker</th>\n",
       "      <th>line</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Caretaker</td>\n",
       "      <td>Season One</td>\n",
       "      <td>CHAKOTAY</td>\n",
       "      <td>(native American with a tattoo) Damage report.</td>\n",
       "      <td>[native, american, with, a, tattoo, damage, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caretaker</td>\n",
       "      <td>Season One</td>\n",
       "      <td>TUVOK</td>\n",
       "      <td>(Vulcan) Shields at sixty percent.</td>\n",
       "      <td>[vulcan, shields, at, sixty, percent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caretaker</td>\n",
       "      <td>Season One</td>\n",
       "      <td>TORRES</td>\n",
       "      <td>(human-Klingon woman) A fuel line has ruptured...</td>\n",
       "      <td>[human, klingon, woman, a, fuel, line, has, ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Caretaker</td>\n",
       "      <td>Season One</td>\n",
       "      <td>CHAKOTAY</td>\n",
       "      <td>Be creative!</td>\n",
       "      <td>[be, creative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Caretaker</td>\n",
       "      <td>Season One</td>\n",
       "      <td>TORRES</td>\n",
       "      <td>How am I supposed to be creative with a thirty...</td>\n",
       "      <td>[how, am, i, supposed, to, be, creative, with,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  episode_name      season   speaker  \\\n",
       "2    Caretaker  Season One  CHAKOTAY   \n",
       "3    Caretaker  Season One     TUVOK   \n",
       "4    Caretaker  Season One    TORRES   \n",
       "5    Caretaker  Season One  CHAKOTAY   \n",
       "6    Caretaker  Season One    TORRES   \n",
       "\n",
       "                                                line  \\\n",
       "2     (native American with a tattoo) Damage report.   \n",
       "3                 (Vulcan) Shields at sixty percent.   \n",
       "4  (human-Klingon woman) A fuel line has ruptured...   \n",
       "5                                       Be creative!   \n",
       "6  How am I supposed to be creative with a thirty...   \n",
       "\n",
       "                                              tokens  \n",
       "2  [native, american, with, a, tattoo, damage, re...  \n",
       "3              [vulcan, shields, at, sixty, percent]  \n",
       "4  [human, klingon, woman, a, fuel, line, has, ru...  \n",
       "5                                     [be, creative]  \n",
       "6  [how, am, i, supposed, to, be, creative, with,...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['4grams'] = [list(nltk.ngrams(t, 4)) for t in df['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, tuple found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-7d74763ab7c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'4grams'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-95-7d74763ab7c5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'4grams'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, tuple found"
     ]
    }
   ],
   "source": [
    "['_'.join(t) for t in [l for l in df['4grams']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"they're\", 'not', 'for', 'sale'),\n",
       " ('not', 'for', 'sale', 'now'),\n",
       " ('for', 'sale', 'now', 'inform'),\n",
       " ('sale', 'now', 'inform', 'your'),\n",
       " ('now', 'inform', 'your', 'commanding'),\n",
       " ('inform', 'your', 'commanding', 'officer'),\n",
       " ('your', 'commanding', 'officer', 'that'),\n",
       " ('commanding', 'officer', 'that', 'the'),\n",
       " ('officer', 'that', 'the', 'federation'),\n",
       " ('that', 'the', 'federation', 'council'),\n",
       " ('the', 'federation', 'council', 'can'),\n",
       " ('federation', 'council', 'can', 'expect'),\n",
       " ('council', 'can', 'expect', 'an'),\n",
       " ('can', 'expect', 'an', 'official'),\n",
       " ('expect', 'an', 'official', 'query')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_4grams = list(nltk.ngrams(df['tokens'].iloc[97], 4))\n",
    "df_4grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4grams = list(nltk.ngrams(book_tokens, 5))\n",
    "book_ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('native', 'american', 'with', 'a'),\n",
       " ('american', 'with', 'a', 'tattoo'),\n",
       " ('with', 'a', 'tattoo', 'damage'),\n",
       " ('a', 'tattoo', 'damage', 'report')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.ngrams(df['tokens'].iloc[0],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
